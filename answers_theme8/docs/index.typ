#import "lib/gost.typ": init

#show: init


+ Этапы представления проекта:
  - подготовительный (презентация идеи и замысла для привлечения партнеров);
  - этап реализации (демонстрация хода работы и промежуточных результатов);
  - заключительный (презентация основных итогов и перспектив развития).

+ Принципы публичного выступления:
  - принцип краткости (выступление на 10–15 минут);
  - принцип последовательности (взаимосвязь всех частей);
  - принцип целенаправленности (логика и соответствие типу проекта);
  - принцип усиления (нарастание воздействия к концу речи);
  - принцип результативности (наличие вывода или призыва).

+ Структура публичного выступления:
  - вступление (обращение и постановка цели);
  - основная часть (изложение информации);
  - заключение (обобщение сказанного).

+ Содержание введения и заключения публичного выступления:
  - введение занимает 5–10% времени и содержит формулировку проблемы, задачи, определения понятий и план речи;
  - заключение занимает около 5% времени и включает итоги, выводы, яркие цитаты или пожелания.

+ Содержание введения в научной работе:
  - обоснование актуальности темы;
  - цель и задачи исследования;
  - объект и предмет исследования;
  - методы исследования;
  - теоретическая значимость и прикладная ценность;
  - краткий обзор литературы по теме.

+ Содержание и объем заключения научной работы:
  - содержит синтез накопленной информации, последовательное изложение итогов в связи с целью и задачами, а также общую оценку проделанной работы;
  - объем составляет 5–7% от основного текста работы.

+ Перечень принятых терминов и его объем:
  - представляет собой алфавитный список определений процессов, явлений и механизмов, используемых в работе;
  - объем составляет 1–2 страницы.

+ Содержание приложений:
  - копии подлинных документов и выдержки из отчетов;
  - анкеты, таблицы, графики и карты;
  - протоколы, инструкции и переписка.

+ Аннотация научной работы и ее объем:
  - краткое обобщение содержания, которое помогает читателю быстро ознакомиться с сутью труда;
  - включает до 10 простых предложений, объем — от половины до 2/3 страницы.

#set heading(numbering: none)

= Задание 10


Библиографическое описание монографии (ГОСТ Р 7.0.100–2018):

*Shu, K.* Detecting Fake News on Social Media = Обнаружение фейковых новостей в социальных медиа / K. Shu, H. Liu. -- Cham : Springer Nature, 2019. -- 129 с. -- (Синтез лекций по анализу данных и поиску знаний). -- ISBN 978-1-68173-582-5. -- Текст : непосредственный.

#show heading: set align(center)

== АННОТАЦИЯ

Монография посвящена проблеме автоматического обнаружения ложных новостей (fake news) в социальных сетях с использованием методов интеллектуального анализа данных (Data Mining) и машинного обучения. Авторы систематизируют теоретические основы дезинформации, рассматривая её как междисциплинарный феномен, затрагивающий психологию, социологию и информатику. В работе подробно описаны алгоритмы анализа контента и социального контекста, а также представлены передовые методы: раннее обнаружение фейков, обучение с частичным привлечением учителя (weakly supervised learning) и объяснимый искусственный интеллект (Explainable AI). Книга содержит обзор реальных датасетов и инструментов, необходимых для разработки систем информационной безопасности.

== ВВЕДЕНИЕ

Актуальность исследования продиктована тем, что социальные сети стали основным каналом потребления новостей, обеспечивая высокую скорость распространения информации при отсутствии традиционных редакционных фильтров. Это создает уязвимости для манипулирования общественным мнением, что делает задачу автоматической фильтрации контента критически важной.

Целью работы является создание комплексной методологии построения интеллектуальных систем для выявления фейковых новостей.

Объектом исследования выступает экосистема социальных медиа, включающая издателей, новостной контент и пользователей.

Предметом исследования являются алгоритмы и модели машинного обучения, способные классифицировать информацию на основе текстовых, визуальных и сетевых признаков.


Задачи монографии включают:
1. Формирование таксономии (классификации) видов фейковых новостей.
2. Анализ признаков, основанных на содержании новости и реакции пользователей (лайки, репосты, комментарии).
3. Разработка методов для выявления фейков на ранних стадиях их распространения.
4. Исследование проблемы интерпретируемости решений нейронных сетей в задачах фактчекинга.

== ПЕРЕЧЕНЬ ПРИНЯТЫХ ТЕРМИНОВ

Раннее обнаружение (Early Detection) — задача выявления фейковой новости на начальном этапе её распространения, когда доступно минимальное количество пользовательских реакций.

Социальный контекст (Social Context) — совокупность данных, окружающих новостной контент, включая профили пользователей, структуру сети распространения и временные метки взаимодействия.

Три-отношение (Tri-relationship) — модель взаимодействия трех ключевых сущностей в новостной экосистеме: Издателя (Publisher), Самой новости (News Article) и Пользователя (Social User).

Эхо-камера (Echo Chamber) — эффект, при котором пользователь получает только ту информацию, которая соответствует его убеждениям, что усиливает поляризацию мнений и доверие к фейкам.

Объяснимость (Explainability) — свойство алгоритма машинного обучения предоставлять понятное человеку обоснование принятого решения (например, почему новость помечена как фейк).

== ЗАКЛЮЧЕНИЕ

В завершении работы авторы подчеркивают, что обнаружение фейковых новостей является сложной задачей, требующей учета не только текста, но и сложных социальных взаимодействий. Основной вывод заключается в том, что наиболее эффективными являются гибридные модели, объединяющие анализ контента (NLP) и анализ графов (Social Network Analysis).

В работе показано, что будущее систем защиты информации лежит в области объяснимого ИИ, так как пользователям важно не просто знать вердикт системы, но и понимать причины его вынесения. Также отмечена важность создания адаптивных моделей, способных обучаться на ограниченных наборах размеченных данных (Weakly Supervised Learning). Для проекта «Детектор» данные выводы обосновывают необходимость внедрения модуля объяснения решений и использования графовых подходов.

#pagebreak()
== ПРИЛОЖЕНИЕ 1
#align(center)[*Классификация методов обнаружения фейковых новостей*]

#table(
  columns: (1fr, 2fr),
  inset: 8pt,
  align: horizon,
  table.header(
    [*Категория*], [*Описание методов*]
  ),
  [На основе контента (Content-based)], [Анализ лингвистических особенностей текста (стилометрия), проверка фактов (knowledge-based) и визуальный анализ изображений.],
  [На основе контекста (Context-based)], [Анализ профилей пользователей (возраст, бот-признаки), анализ распространения (каскады репостов) и анализ реакции аудитории (тональность комментариев).]
)

== ПРИЛОЖЕНИЕ 2
#align(center)[*Популярные датасеты для обучения моделей*]

1. *BuzzFeedNews:* Набор данных, содержащий новости с Facebook, связанные с выборами в США 2016 года, размеченные журналистами как «фейк» или «правда».
2. *LIAR:* Масштабный датасет (12.8 тыс. утверждений), собранный с ресурса PolitiFact, с шестью градациями правдивости.
3. *FakeNewsNet:* Датасет, включающий не только тексты новостей, но и структуру социальных графов их распространения (Twitter), что критически важно для анализа контекста.
4. *CREDBANK:* Краудсорсинговый датасет, содержащий более 60 миллионов твитов, связанных с новостными событиями, с оценкой достоверности.
